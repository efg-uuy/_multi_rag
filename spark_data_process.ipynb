{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860c4566",
   "metadata": {},
   "source": [
    "# 用于处理多模态RAG图文问答挑战赛训练集JSON文件，提取问题与答案构建QA对\n",
    "本notebook将演示如何将原始训练集转换为标准QA格式，便于后续微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b72abf",
   "metadata": {},
   "outputs": [],
   "source": "#"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict, List, Any\n",
    "from transformers import pipeline\n",
    "\n",
    "# 金融领域实体词表（可根据实际数据扩展）\n",
    "FINANCIAL_ENTITIES = {\n",
    "    \"指标\": [\"营收\", \"净利润\", \"毛利率\", \"资产负债率\", \"ROE\", \"同比增长率\", \"环比增长率\"],\n",
    "    \"主体\": [\"公司\", \"企业\", \"银行\", \"基金\", \"股票\", \"债券\"],\n",
    "    \"文档类型\": [\"财报\", \"研报\", \"年报\", \"季报\", \"公告\"]\n",
    "}\n",
    "\n",
    "def extract_finance_entities(text: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"提取文本中的金融实体，增强领域对齐\"\"\"\n",
    "    entities = {\"指标\": [], \"主体\": [], \"文档类型\": []}\n",
    "    for category, keywords in FINANCIAL_ENTITIES.items():\n",
    "        for keyword in keywords:\n",
    "            if re.search(rf\"\\b{re.escape(keyword)}\\b\", text):\n",
    "                entities[category].append(keyword)\n",
    "    # 去重并保持顺序\n",
    "    for k in entities:\n",
    "        entities[k] = list(dict.fromkeys(entities[k]))\n",
    "    return entities\n",
    "\n",
    "def is_answer_consistent(question: str, answer: str, context: str = \"\") -> bool:\n",
    "    \"\"\"增强版答案校验：确保答案非空、含来源且与上下文一致\"\"\"\n",
    "    if not answer.strip():\n",
    "        return False\n",
    "\n",
    "    # 检查是否包含来源引用（匹配文件名和页码格式）\n",
    "    if not re.search(r\"(.+?\\.pdf).*?(第\\d+页)\", answer):\n",
    "        # 若未直接引用，检查是否能从上下文中找到依据\n",
    "        if context and not any(ent in answer for ent in extract_finance_entities(context).get(\"指标\", [])):\n",
    "            return False\n",
    "        return True  # 允许无显式引用但有实体关联的情况\n",
    "    return True\n",
    "\n",
    "def augment_data(context):\n",
    "    \"\"\"基于财报内容生成问题，增强训练数据\"\"\"\n",
    "    try:\n",
    "        qg_pipeline = pipeline(\"text2text-generation\", model=\"lmqg/t5-base-finance-qg\")\n",
    "        questions = qg_pipeline(context, max_length=100, num_return_sequences=2)  # 生成2个问题\n",
    "        return [{\"context\": context, \"question\": q[\"generated_text\"], \"answer\": \"\"} for q in questions]\n",
    "    except Exception as e:\n",
    "        print(f\"问题生成失败: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def build_finance_sft_data(raw_data: List[Dict[str, Any]], chunk_data_path: str = \"all_pdf_page_chunks.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"构建增强版金融SFT数据，关联PDF上下文\"\"\"\n",
    "    # 加载PDF分页内容（从步骤1处理结果获取）\n",
    "    chunk_context = {}\n",
    "    if os.path.exists(chunk_data_path):\n",
    "        with open(chunk_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            chunks = json.load(f)\n",
    "            for chunk in chunks:\n",
    "                key = f\"{chunk['metadata']['file_name']}_page_{chunk['metadata']['page']}\"\n",
    "                chunk_context[key] = chunk['content']\n",
    "        print(f\"已加载 {len(chunk_context)} 条PDF分页上下文\")\n",
    "\n",
    "    sft_data = []\n",
    "    # 先处理原始数据\n",
    "    for item in raw_data:\n",
    "        # 1. 金融助手角色强化\n",
    "        system_prompt = (\n",
    "            \"你是专业金融分析师助手，需基于财报、研报等金融文档内容回答问题。\"\n",
    "            \"要求：1. 严格使用规范金融术语；2. 数据需标注来源（如XX.pdf第X页）；\"\n",
    "            \"3. 区分事实陈述与分析观点；4. 图表相关问题需结合数据趋势解读。\"\n",
    "        )\n",
    "\n",
    "        # 2. 细化金融任务类型\n",
    "        question = item.get(\"question\", \"\").lower()\n",
    "        task_type = \"金融问答\"\n",
    "        if any(ind in question for ind in FINANCIAL_ENTITIES[\"指标\"]):\n",
    "            task_type = \"财务指标提取\"\n",
    "        elif \"同比\" in question or \"环比\" in question or \"趋势\" in question:\n",
    "            task_type = \"数据趋势分析\"\n",
    "        elif \"解释\" in question or \"含义\" in question:\n",
    "            task_type = \"金融术语解读\"\n",
    "        elif \"图表\" in question or \"图形\" in question or \"表格\" in question:\n",
    "            task_type = \"图文分析\"  # 适配多模态场景\n",
    "\n",
    "        # 3. 获取关联的PDF上下文\n",
    "        file_name = item.get(\"file_name\", \"未知\")\n",
    "        page = item.get(\"page\", \"未知\")\n",
    "        context_key = f\"{file_name}_page_{page}\"\n",
    "        context = chunk_context.get(context_key, \"\")\n",
    "\n",
    "        # 4. 答案一致性校验（结合上下文）\n",
    "        answer = item.get(\"answer\", \"\")\n",
    "        if not is_answer_consistent(question, answer, context):\n",
    "            print(f\"过滤不一致样本: {question[:30]}...\")\n",
    "            continue\n",
    "\n",
    "        # 5. 提取金融实体\n",
    "        entities = extract_finance_entities(question + \" \" + answer)\n",
    "\n",
    "        sft_data.append({\n",
    "            \"system\": system_prompt,\n",
    "            \"instruction\": question,\n",
    "            \"context\": context,  # 新增：关联的PDF上下文\n",
    "            \"output\": answer,\n",
    "            \"task_type\": task_type,\n",
    "            \"entities\": entities,  # 新增：提取的金融实体\n",
    "            \"metadata\": {\n",
    "                \"file_name\": file_name,\n",
    "                \"page\": page,\n",
    "                \"has_image\": \"图表\" in question or \"图形\" in question  # 标记多模态样本\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # 数据增强：基于上下文生成新问题\n",
    "    print(\"开始进行数据增强...\")\n",
    "    augmented_samples = []\n",
    "    for item in sft_data:\n",
    "        if item[\"context\"]:  # 只有有上下文的样本才进行增强\n",
    "            generated = augment_data(item[\"context\"])\n",
    "            for gen in generated:\n",
    "                # 复用原样本的元数据和上下文\n",
    "                augmented_samples.append({\n",
    "                    \"system\": item[\"system\"],\n",
    "                    \"instruction\": gen[\"question\"],\n",
    "                    \"context\": item[\"context\"],\n",
    "                    \"output\": item[\"output\"],  # 使用原样本答案作为参考\n",
    "                    \"task_type\": item[\"task_type\"],\n",
    "                    \"entities\": item[\"entities\"],\n",
    "                    \"metadata\": item[\"metadata\"]\n",
    "                })\n",
    "\n",
    "    print(f\"数据增强完成，新增 {len(augmented_samples)} 个样本\")\n",
    "    sft_data.extend(augmented_samples)\n",
    "\n",
    "    return sft_data\n",
    "\n",
    "def main():\n",
    "    # 1. 定义文件路径（使用提供的绝对路径）\n",
    "    train_data_path = r\"D:\\AI读pdf\\spark_multi_rag\\data\\train.json\"\n",
    "    test_data_path = r\"D:\\AI读pdf\\spark_multi_rag\\data\\test.json\"\n",
    "    chunk_data_path = r\"D:\\AI读pdf\\spark_multi_rag\\all_pdf_page_chunks.json\"  # 步骤1处理结果\n",
    "    output_dir = r\"D:\\AI读pdf\\spark_multi_rag\\data\"\n",
    "\n",
    "    # 2. 加载原始数据集（比赛训练集）\n",
    "    if not os.path.exists(train_data_path):\n",
    "        raise FileNotFoundError(f\"未找到训练集: {train_data_path}，请检查文件路径\")\n",
    "\n",
    "    with open(train_data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = json.load(f)\n",
    "    print(f\"原始样本数量: {len(raw_data)}\")\n",
    "    if raw_data:\n",
    "        print(\"示例原始样本:\", json.dumps(raw_data[0], ensure_ascii=False)[:200] + \"...\")\n",
    "\n",
    "    # 3. 检查PDF上下文文件\n",
    "    if not os.path.exists(chunk_data_path):\n",
    "        print(f\"警告：未找到PDF上下文文件 {chunk_data_path}，请先运行步骤1的PDF处理脚本\")\n",
    "\n",
    "    # 4. 构建金融SFT数据\n",
    "    finance_sft_data = build_finance_sft_data(raw_data, chunk_data_path)\n",
    "    print(f\"处理后SFT样本数量: {len(finance_sft_data)}\")\n",
    "    if finance_sft_data:\n",
    "        print(\"示例SFT样本:\", json.dumps(finance_sft_data[0], ensure_ascii=False)[:300] + \"...\")\n",
    "\n",
    "    # 5. 保存处理结果\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 保存为JSON（供微调使用）\n",
    "    sft_json_path = os.path.join(output_dir, \"finance_sft_train.json\")\n",
    "    with open(sft_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(finance_sft_data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"已保存金融SFT JSON文件: {sft_json_path}\")\n",
    "\n",
    "    # 保存为CSV（便于数据分析）\n",
    "    sft_df = pd.DataFrame(finance_sft_data)\n",
    "    sft_csv_path = os.path.join(output_dir, \"finance_sft_train.csv\")\n",
    "    sft_df.to_csv(sft_csv_path, index=False, encoding=\"utf-8-sig\")  # 使用utf-8-sig避免中文乱码\n",
    "    print(f\"已保存金融SFT CSV文件: {sft_csv_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "1497c97b9e5cd88a"
  },
  {
   "cell_type": "markdown",
   "id": "c4f53530",
   "metadata": {},
   "source": [
    "## 2. 加载JSON数据集\n",
    "读取多模态RAG图文问答挑战赛训练集.json文件，解析为Python对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf8a438",
   "metadata": {},
   "source": [
    "## 4. 构建QA对列表\n",
    "遍历数据集，将每条数据的question和answer字段提取出来，构建QA对列表。指令字段统一设置为“你是一名专业的财报数据问答助手”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5f6cf",
   "metadata": {},
   "source": [
    "## 5. 保存处理后的QA数据\n",
    "将处理后的QA对列表保存为新的JSON或CSV文件，便于后续模型训练或分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13474168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
